<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Testing-S2S Live</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif; margin: 24px; background: #f8f9fa; }
    .container { max-width: 800px; margin: 0 auto; background: white; padding: 24px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }
    #status { margin: 12px 0; padding: 8px 12px; border-radius: 4px; font-weight: 500; }
    .status-connected { background: #d4edda; color: #155724; }
    .status-error { background: #f8d7da; color: #721c24; }
    .status-idle { background: #e2e3e5; color: #383d41; }
    .row { margin: 16px 0; }
    label { display: block; margin-bottom: 6px; font-weight: 500; }
    input[type=text] { width: 100%; padding: 8px; border: 1px solid #ced4da; border-radius: 4px; }
    input[type=range] { width: 200px; }
    button { padding: 10px 20px; margin-right: 10px; border: none; border-radius: 4px; cursor: pointer; font-weight: 500; }
    button:disabled { opacity: 0.6; cursor: not-allowed; }
    .btn-start { background: #28a745; color: white; }
    .btn-stop { background: #dc3545; color: white; }
    .btn-mute { background: #6c757d; color: white; }
    #logs { height: 300px; overflow: auto; background: #f8f9fa; border: 1px solid #dee2e6; padding: 12px; font-family: 'Monaco', 'Courier New', monospace; font-size: 12px; white-space: pre-wrap; }
    .audio-controls { margin: 16px 0; padding: 12px; background: #e9ecef; border-radius: 4px; }
    .volume-control { display: inline-block; margin-left: 15px; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéß Testing-S2S Live</h1>
    <div id="status" class="status-idle">Idle - Click Start to begin</div>
    
    <div class="row">
      <label>WebSocket URL:</label>
      <input id="wsUrl" type="text" value="" placeholder="Auto-detected..." />
    </div>
    
    <div class="audio-controls">
      <div class="row">
        <button id="start" class="btn-start">üé§ Start Audio</button>
        <button id="stop" class="btn-stop" disabled>‚èπÔ∏è Stop</button>
        <button id="mute" class="btn-mute">üîä Mute</button>
        <div class="volume-control">
          <label>Volume:</label>
          <input id="volume" type="range" min="0" max="100" value="90" />
          <span id="volumeValue">90%</span>
        </div>
      </div>
      <small>üìù <strong>Instructions:</strong> Click Start, allow microphone, speak and pause to hear AI response in turn mode.</small>
    </div>
    
    <div class="row">
      <label>Connection Logs:</label>
      <div id="logs"></div>
    </div>
  </div>

<script>
const statusEl = document.getElementById('status');
const logsEl = document.getElementById('logs');
const wsUrlEl = document.getElementById('wsUrl');
const startBtn = document.getElementById('start');
const stopBtn = document.getElementById('stop');
const muteBtn = document.getElementById('mute');
const volumeSlider = document.getElementById('volume');
const volumeValue = document.getElementById('volumeValue');

let ws = null, media = null, ctx = null, proc = null, gain = null;
let scheduleTime = 0; // Gapless playback timeline
let isMuted = false;

// Auto-detect WebSocket URL
function detectWebSocketUrl() {
    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
    const host = window.location.host;
    return `${protocol}//${host}/ws/stream`;
}

// Set auto-detected URL on load
window.addEventListener('load', () => {
    const autoUrl = detectWebSocketUrl();
    wsUrlEl.value = autoUrl;
    log(`üîç Auto-detected WebSocket URL: ${autoUrl}`);
});

function setStatus(text, className) {
    statusEl.textContent = text;
    statusEl.className = className;
}

function log(m) { 
    const timestamp = new Date().toLocaleTimeString();
    logsEl.textContent += `[${timestamp}] ${m}\n`; 
    logsEl.scrollTop = logsEl.scrollHeight; 
}

function f32_to_i16(f) {
    const b = new ArrayBuffer(f.length * 2);
    const v = new DataView(b);
    let o = 0;
    for (let i = 0; i < f.length; i++, o += 2) {
        let s = Math.max(-1, Math.min(1, f[i]));
        v.setInt16(o, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
    }
    return b;
}

// Gapless audio playback with proper scheduling
function playAudioFrame(audioData) {
    try {
        const i16 = new Int16Array(audioData);
        const f32 = new Float32Array(i16.length);
        for (let i = 0; i < i16.length; i++) {
            f32[i] = i16[i] / 32768.0;
        }
        
        // Create buffer at correct sample rate
        const buffer = ctx.createBuffer(1, f32.length, 24000);
        buffer.getChannelData(0).set(f32);
        
        // Gapless scheduling: maintain continuous timeline
        const now = ctx.currentTime;
        if (scheduleTime < now) {
            scheduleTime = now;
        }
        
        // Create source and schedule
        const source = ctx.createBufferSource();
        source.buffer = buffer;
        source.connect(gain); // Connect to gain node, not directly to destination
        source.start(scheduleTime);
        
        // Advance timeline by buffer duration
        const duration = f32.length / 24000;
        scheduleTime += duration;
        
        log(`üîä Scheduled audio: ${i16.length} samples (${(duration*1000).toFixed(1)}ms) at ${scheduleTime.toFixed(3)}s`);
        
    } catch (e) {
        log(`‚ùå Audio playback error: ${e.message}`);
        console.error('Audio playback error:', e);
    }
}

// Update volume
function updateVolume() {
    const vol = parseInt(volumeSlider.value) / 100;
    volumeValue.textContent = `${volumeSlider.value}%`;
    if (gain) {
        gain.gain.setValueAtTime(isMuted ? 0 : vol, ctx.currentTime);
    }
}

// Toggle mute
function toggleMute() {
    isMuted = !isMuted;
    muteBtn.textContent = isMuted ? 'üîá Unmute' : 'üîä Mute';
    updateVolume();
    log(isMuted ? 'üîá Audio muted' : 'üîä Audio unmuted');
}

async function start() {
    const url = wsUrlEl.value.trim();
    if (!url) {
        alert('‚ùå Please enter WebSocket URL');
        return;
    }
    
    try {
        log('üîå Connecting to WebSocket...');
        setStatus('Connecting...', 'status-idle');
        
        // Setup AudioContext first
        ctx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
        
        // Force resume AudioContext (browser autoplay policy)
        if (ctx.state === 'suspended') {
            log('üîÑ Resuming suspended AudioContext...');
            await ctx.resume();
        }
        log(`üéµ AudioContext state: ${ctx.state}, sampleRate: ${ctx.sampleRate}`);
        
        // Create master gain node
        gain = ctx.createGain();
        gain.connect(ctx.destination);
        updateVolume();
        log('üéöÔ∏è Audio gain node created');
        
        // Reset playback timeline
        scheduleTime = ctx.currentTime;
        log(`‚è∞ Playback timeline initialized at ${scheduleTime.toFixed(3)}s`);
        
        ws = new WebSocket(url);
        ws.binaryType = 'arraybuffer';
        
        ws.onopen = () => {
            log('‚úÖ WebSocket connected successfully');
            setStatus('Connected - Ready for audio', 'status-connected');
        };
        
        ws.onclose = (event) => {
            log(`‚ùå WebSocket closed (code: ${event.code}, reason: ${event.reason})`);
            setStatus('Connection closed', 'status-error');
        };
        
        ws.onerror = (error) => {
            log('‚ùå WebSocket error occurred');
            console.error('WebSocket error:', error);
            setStatus('Connection error', 'status-error');
        };
        
        ws.onmessage = (ev) => {
            if (!(ev.data instanceof ArrayBuffer)) {
                log('‚ö†Ô∏è Received non-binary data');
                return;
            }
            
            // Use gapless playback scheduler
            playAudioFrame(ev.data);
        };
        
        // Request microphone access
        log('üé§ Requesting microphone access...');
        media = await navigator.mediaDevices.getUserMedia({
            audio: {
                channelCount: 1,
                sampleRate: 24000,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            }
        });
        
        log('‚úÖ Microphone access granted');
        
        // Setup audio input processing
        const source = ctx.createMediaStreamSource(media);
        proc = ctx.createScriptProcessor(2048, 1, 1);
        
        proc.onaudioprocess = (e) => {
            if (!ws || ws.readyState !== WebSocket.OPEN) return;
            
            // Ensure AudioContext stays active
            if (ctx.state === 'suspended') {
                ctx.resume();
            }
            
            const inputData = e.inputBuffer.getChannelData(0);
            const chunkSize = 1920; // 80ms at 24kHz
            
            for (let i = 0; i < inputData.length; i += chunkSize) {
                const slice = inputData.subarray(i, Math.min(i + chunkSize, inputData.length));
                if (slice.length > 0) {
                    const buffer = f32_to_i16(slice);
                    ws.send(buffer);
                }
            }
        };
        
        source.connect(proc);
        proc.connect(ctx.destination);
        
        log('üéµ Audio pipeline ready - speak now!');
        setStatus('üé§ Listening... (speak and pause for response)', 'status-connected');
        
        startBtn.disabled = true;
        stopBtn.disabled = false;
        
    } catch (err) {
        log(`‚ùå Error during setup: ${err.message}`);
        setStatus('Setup failed', 'status-error');
        console.error('Setup error:', err);
        stop();
    }
}

function stop() {
    if (proc) {
        proc.disconnect();
        proc = null;
        log('üîá Audio processor disconnected');
    }
    if (gain) {
        gain.disconnect();
        gain = null;
        log('üéöÔ∏è Gain node disconnected');
    }
    if (ctx && ctx.state !== 'closed') {
        ctx.close();
        ctx = null;
        log('üîá Audio context closed');
    }
    if (media) {
        media.getTracks().forEach(track => {
            track.stop();
            log(`üõë Stopped ${track.kind} track`);
        });
        media = null;
    }
    if (ws) {
        ws.close();
        ws = null;
        log('üîå WebSocket disconnected');
    }
    
    scheduleTime = 0;
    startBtn.disabled = false;
    stopBtn.disabled = true;
    setStatus('Stopped', 'status-idle');
}

startBtn.onclick = start;
stopBtn.onclick = stop;
muteBtn.onclick = toggleMute;
volumeSlider.oninput = updateVolume;

// Initialize
document.addEventListener('DOMContentLoaded', () => {
    log('üöÄ Testing-S2S Web Interface Ready');
    log('üí° Tip: Make sure server is running with REPLY_MODE=turn for best experience');
});

// Auto-retry connection on failure
let retryCount = 0;
function attemptReconnect() {
    if (retryCount < 3) {
        retryCount++;
        log(`üîÑ Auto-retry attempt ${retryCount}/3 in 2s...`);
        setTimeout(() => {
            if (!ws || ws.readyState === WebSocket.CLOSED) {
                start();
            }
        }, 2000);
    }
}

// Handle browser tab focus for AudioContext resume
document.addEventListener('visibilitychange', () => {
    if (!document.hidden && ctx && ctx.state === 'suspended') {
        ctx.resume().then(() => {
            log('üîÑ AudioContext resumed after tab focus');
        });
    }
});
</script>
</body>
</html>